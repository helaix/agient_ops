# Unstructured Feedback Guidelines

This document provides guidelines for collecting and managing unstructured feedback on agent performance. Unstructured feedback offers valuable insights that might not fit into predefined categories, allowing for more flexible and nuanced input.

## Table of Contents

1. [Introduction](#introduction)
2. [When to Use Unstructured Feedback](#when-to-use-unstructured-feedback)
3. [Collection Methods](#collection-methods)
4. [Prompting Strategies](#prompting-strategies)
5. [Processing Guidelines](#processing-guidelines)
6. [Integration with Structured Feedback](#integration-with-structured-feedback)
7. [Example Templates](#example-templates)

## Introduction

Unstructured feedback refers to open-ended, free-form input that isn't constrained by predefined questions or rating scales. This type of feedback can capture unexpected insights, nuanced observations, and creative suggestions that might be missed in structured formats. While more challenging to analyze systematically, unstructured feedback is invaluable for discovering new perspectives and understanding the full context of user experiences.

## When to Use Unstructured Feedback

Unstructured feedback is particularly valuable in the following situations:

### Exploratory Phases

- When you're not sure what aspects of performance are most important
- During early development or significant changes when user reactions are unpredictable
- When exploring new use cases or applications

### Complex Interactions

- For evaluating complex, multi-step interactions
- When assessing creative or non-standard agent outputs
- In situations with many variables or contextual factors

### Emotional or Experiential Aspects

- When capturing user feelings and emotional responses
- For understanding the overall user experience
- When assessing trust, comfort, or satisfaction

### Supplementary Insights

- As a complement to structured feedback
- When seeking deeper explanations for quantitative ratings
- To capture "why" behind user behaviors or reactions

## Collection Methods

### Open-Ended Questions

Simple, open-ended questions that invite detailed responses:

- "What was your experience working with this agent?"
- "What aspects of the agent's performance stood out to you?"
- "How did the agent help or hinder your work?"
- "What would you change about how the agent operates?"
- "Describe your ideal interaction with this type of agent."

### Guided Narratives

Prompts that guide users through telling a story about their experience:

- "Walk me through your most recent interaction with the agent from start to finish."
- "Describe a moment when the agent exceeded or fell short of your expectations."
- "Tell me about how your workflow has changed since you started using this agent."
- "Explain how you and the agent collaborated to solve a problem."

### Contextual Feedback

Collecting feedback within the context of specific interactions:

- In-the-moment reaction capture during or immediately after interactions
- Contextual prompts based on specific agent actions or outputs
- Environment-aware feedback collection that considers the user's current task

### Multimedia Feedback

Alternative formats beyond text:

- Voice recordings of user thoughts and reactions
- Video captures of interactions with commentary
- Annotated screenshots or interaction logs
- Sketches or diagrams of desired workflows or improvements

## Prompting Strategies

### Effective Prompting Techniques

Strategies to elicit useful unstructured feedback:

#### Open but Focused

- Start with open questions but provide some focus
- Example: "Tell me about your experience using the agent for data analysis tasks."

#### Laddering

- Start broad, then progressively narrow with follow-up questions
- Example: "What stood out about your interaction? → What specifically about that feature was helpful? → How did that help with your particular task?"

#### Contrast Questions

- Ask users to compare and contrast different aspects
- Example: "How does this agent compare to other tools you use for similar tasks?"

#### Hypothetical Scenarios

- Present hypothetical situations to explore preferences
- Example: "If you could change three things about how the agent works, what would they be?"

#### Appreciative Inquiry

- Focus on positive aspects to understand what works well
- Example: "Describe a time when this agent was particularly helpful. What made that interaction successful?"

### Avoiding Biased Prompts

Guidelines to prevent leading or biasing feedback:

- **Avoid Leading Questions**: "Don't you think the agent is much faster now?" → "How would you describe the agent's speed?"
- **Neutral Language**: Use neutral terms rather than evaluative ones
- **Balanced Options**: When suggesting possibilities, present multiple perspectives
- **Open to Criticism**: Explicitly encourage constructive criticism
- **Diverse Perspectives**: Seek feedback from various viewpoints and experiences

## Processing Guidelines

### Initial Processing

Steps for processing raw unstructured feedback:

1. **Documentation**
   - Record feedback verbatim when possible
   - Preserve context information (user role, interaction scenario, etc.)
   - Note collection method and any prompts used

2. **Initial Review**
   - Read through all feedback without immediate categorization
   - Note initial impressions and potential themes
   - Identify feedback requiring immediate attention

3. **Basic Categorization**
   - Tag feedback with basic categories (positive/negative, feature area, etc.)
   - Identify actionable vs. non-actionable feedback
   - Flag feedback needing clarification or follow-up

### Analysis Approaches

Methods for deriving insights from unstructured feedback:

#### Thematic Analysis

- Identify recurring themes and patterns across feedback
- Develop coding schemes to categorize feedback segments
- Analyze relationships between different themes
- Quantify theme frequency and distribution

#### Sentiment Analysis

- Assess emotional tone and intensity
- Identify particularly positive or negative reactions
- Track sentiment changes over time or across features
- Connect sentiment to specific agent capabilities or behaviors

#### Narrative Analysis

- Analyze the structure and flow of user stories
- Identify key turning points or decision moments
- Understand user mental models and expectations
- Extract implicit needs and values

#### Linguistic Analysis

- Examine word choice and language patterns
- Identify frequently used terms or phrases
- Analyze metaphors and analogies
- Note terminology gaps or misalignments

### Synthesis and Integration

Approaches for synthesizing insights from multiple feedback sources:

- **Cross-validation**: Confirm findings across multiple feedback instances
- **Pattern Recognition**: Identify consistent patterns across diverse feedback
- **Contextual Grouping**: Group feedback by relevant contexts or scenarios
- **Insight Mapping**: Connect feedback insights to specific agent components
- **Priority Assessment**: Evaluate the significance and actionability of findings

## Integration with Structured Feedback

### Complementary Approaches

How to use unstructured and structured feedback together:

- **Sequential Integration**: Use unstructured feedback to inform structured feedback design
- **Parallel Collection**: Collect both types simultaneously for comprehensive insights
- **Explanatory Connection**: Use unstructured feedback to explain structured ratings
- **Validation Pairing**: Validate findings from one approach with the other
- **Comprehensive Reporting**: Present integrated findings from both approaches

### Conversion Strategies

Methods for converting unstructured feedback into more structured formats:

- **Theme Quantification**: Count occurrences of identified themes
- **Sentiment Scoring**: Convert sentiment analysis into numerical scores
- **Feature Mapping**: Map narrative feedback to specific feature categories
- **Issue Extraction**: Identify and categorize specific issues mentioned
- **Suggestion Categorization**: Organize improvement suggestions by type

## Example Templates

### Minimal Unstructured Feedback Template

A simple template for collecting basic unstructured feedback:

```
# Agent Feedback

## Your Experience
Please share your thoughts about your experience with this agent:

[Open text field]

## Additional Comments
Is there anything else you'd like us to know?

[Open text field]

## About You
- How often do you use this agent? [Rarely / Occasionally / Regularly / Frequently]
- Your primary use case: [Short text field]
```

### Comprehensive Unstructured Feedback Template

A more detailed template for in-depth unstructured feedback:

```
# Comprehensive Agent Feedback

## General Experience
Please describe your overall experience working with this agent:

[Open text field]

## Specific Scenarios
Please describe a specific instance where the agent:

### Performed particularly well:

[Open text field]

### Could have performed better:

[Open text field]

## Impact on Your Work
How has this agent affected your work processes and outcomes?

[Open text field]

## Suggestions
What changes or improvements would make this agent more valuable to you?

[Open text field]

## Future Capabilities
What additional capabilities would you like to see in this agent?

[Open text field]

## Comparative Perspective
How does this agent compare to other tools or methods you've used for similar tasks?

[Open text field]

## Context Information
- Your role: [Short text field]
- Experience level with this type of agent: [Beginner / Intermediate / Advanced]
- Primary use cases: [Short text field]
- Frequency of use: [Daily / Weekly / Monthly / Rarely]
```

### Guided Narrative Template

A template focused on eliciting user stories:

```
# Agent Experience Narrative

We'd like to understand your experience with our agent through your own story.

## Your Recent Experience
Please walk us through a recent interaction you had with the agent:

### What were you trying to accomplish?

[Open text field]

### How did you engage with the agent?

[Open text field]

### What happened during the interaction?

[Open text field]

### What was the outcome?

[Open text field]

### How did you feel about this experience?

[Open text field]

## Reflection
Looking back on this experience:

### What worked well?

[Open text field]

### What could have been better?

[Open text field]

### What surprised you?

[Open text field]

## Looking Forward
Based on this experience:

### How likely are you to use the agent again for similar tasks?
[Very unlikely / Unlikely / Neutral / Likely / Very likely]

### Why?

[Open text field]
```

### Contextual Feedback Prompt

A template for collecting feedback immediately after specific interactions:

```
# Quick Reaction

## We noticed you just completed [specific task] with our agent.

### How would you describe this interaction in a few words?

[Short text field]

### What was the most helpful aspect?

[Open text field]

### What was the most challenging aspect?

[Open text field]

### Is there anything you wish the agent had done differently?

[Open text field]

### Would you like to schedule a brief follow-up conversation about your experience?
[ ] Yes, please contact me
[ ] No, thank you
```

## Implementation Tips

### For Feedback Collectors

- **Create Psychological Safety**: Ensure users feel comfortable providing honest feedback
- **Appropriate Timing**: Collect feedback at optimal moments in the user journey
- **Respect User Time**: Balance depth with reasonable time commitments
- **Provide Context**: Explain how feedback will be used to improve the agent
- **Follow Up**: Circle back on valuable feedback with additional questions
- **Show Impact**: Demonstrate how previous feedback has led to improvements

### For Feedback Analyzers

- **Preserve Nuance**: Maintain the richness of unstructured feedback during analysis
- **Look for Surprises**: Pay special attention to unexpected or novel insights
- **Connect Dots**: Identify relationships between different feedback points
- **Consider Context**: Interpret feedback within its full context
- **Avoid Over-interpretation**: Be careful not to project meanings not present in the feedback
- **Balance Outliers and Patterns**: Consider both unique perspectives and common themes

